# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KWiKYiHl4ucpIeTG2OFBoZeXBlYFHSEM
"""

# ================================================================
# High-Altitude Balloon Ensemble Model for Atmospheric Forecasting
#
# Nick Bloor
#
# 11/3/2025
# ================================================================

# --- 1. Import Libraries ---
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor
from sklearn.linear_model import RidgeCV
from sklearn.metrics import mean_absolute_error, r2_score
import xgboost as xgb
import matplotlib.pyplot as plt

# --- 2. Load and Merge Datasets ---
files = {
    "Roswell": "PTER_NEMCC_101423_1452.csv",
    "Carbondale": "PTER_NEMCC_040824_.1729.xls",
    "Stratostar": "Stratostar Eclipse Flight.csv"
}

df_list = []
for site, path in files.items():
    if path.endswith(".csv"):
        df = pd.read_csv(path)
    elif path.endswith(".xlsx"):
        df = pd.read_excel(path, engine="openpyxl")  # modern Excel
    elif path.endswith(".xls"):
        df = pd.read_excel(path, engine="xlrd")      # legacy Excel
    else:
        raise ValueError(f"Unsupported file format: {path}")

    df["Site"] = site
    df_list.append(df)

data = pd.concat(df_list, ignore_index=True)


# --- 3. Data Cleaning ---
# Drop duplicate columns, handle missing values, and remove outliers
data = data.replace([-999, 'NaN', ''], np.nan)
data = data.dropna(subset=["Alt(M)", "extT(C)", "msPress(ATM)"])

# Convert units or enforce numeric
cols_to_numeric = ["Alt(M)", "extT(C)", "msPress(ATM)", "VertVel(M/S)", "GndSpd(M/S)", "Head(Deg)"]
for c in cols_to_numeric:
    data[c] = pd.to_numeric(data[c], errors='coerce')

# --- 4. Feature Engineering ---
# Example derived features:
data["Temp_Grad"] = data["extT(C)"].diff() / data["Alt(M)"].diff()      # temperature lapse rate
data["Press_Grad"] = data["msPress(ATM)"].diff() / data["Alt(M)"].diff()
data["Wind_Shear"] = data["VertVel(M/S)"].diff().abs()                  # vertical shear magnitude
data["Flight_Time_Sec"] = pd.to_numeric(data["T(Sec)"], errors='coerce')

# Drop rows with NaNs from differencing
data = data.dropna(subset=["Temp_Grad", "Press_Grad", "Wind_Shear"])

# --- 5. Define Target and Features ---
# Example: Predict vertical velocity or wind shear magnitude
target = "VertVel(M/S)"
features = [
    "Alt(M)", "extT(C)", "msPress(ATM)",
    "Temp_Grad", "Press_Grad", "GndSpd(M/S)", "Head(Deg)"
]

X = data[features]
y = data[target]

# --- 6. Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 7. Scaling ---
# --- Clean the data ---
# Replace inf, -inf with NaN
X_train = X_train.replace([np.inf, -np.inf], np.nan)
X_test = X_test.replace([np.inf, -np.inf], np.nan)

# Drop columns with all NaNs (if any)
X_train = X_train.dropna(axis=1, how="all")
X_test = X_test.dropna(axis=1, how="all")

# Fill remaining NaNs with column means (or medians)
X_train = X_train.fillna(X_train.mean())
X_test = X_test.fillna(X_train.mean())  # use train means to avoid data leakage

# --- Scaling ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- 8. Define Base Models ---
rf = RandomForestRegressor(n_estimators=200, random_state=42)
gb = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05)
xg = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=5)

# --- 9. Ensemble (Stacking Regressor) ---
stack = StackingRegressor(
    estimators=[
        ("rf", rf),
        ("gb", gb),
        ("xgb", xg)
    ],
    final_estimator=RidgeCV()
)

# --- 10. Train Ensemble ---
stack.fit(X_train_scaled, y_train)

# --- 11. Evaluate ---
preds = stack.predict(X_test_scaled)
print("MAE:", mean_absolute_error(y_test, preds))
print("RÂ²:", r2_score(y_test, preds))

# --- 12. Visualize Results ---
plt.figure(figsize=(6,6))
plt.scatter(y_test, preds, alpha=0.5)
plt.xlabel("Observed Vertical Velocity (m/s)")
plt.ylabel("Predicted Vertical Velocity (m/s)")
plt.title("Ensemble Model Performance on Balloon Data")
plt.grid(True)
plt.show()

# --- 13. Feature Importance (from RF or XGB) ---
importances = rf.feature_importances_
feature_imp = pd.Series(importances, index=features).sort_values(ascending=False)
feature_imp.plot(kind='barh', title='Feature Importance (Random Forest)')
plt.show()